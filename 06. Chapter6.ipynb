{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNueU925kW1DCHqYUhUJiYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keripikkaneboo/Hands-On-Machine-Learning-O-Reilly-/blob/main/06.%20Chapter6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bab 6: Decision Trees\n",
        "\n",
        "Bab ini membahas **Decision Trees**, sebuah algoritma yang kuat dan serbaguna yang mampu melakukan tugas klasifikasi, regresi, dan bahkan multioutput. Decision Trees juga merupakan komponen dasar dari **Random Forests**.\n",
        "\n",
        "* **Pelatihan dan Visualisasi**: Decision Tree adalah model yang intuitif. Model ini belajar dengan membuat serangkaian pertanyaan sederhana tentang data. Hasilnya adalah sebuah struktur seperti pohon di mana setiap *node* internal merepresentasikan sebuah tes pada sebuah fitur, dan setiap *leaf node* (daun) merepresentasikan sebuah hasil (kelas atau nilai). Salah satu kelebihan utamanya adalah hasilnya mudah diinterpretasikan (*white box model*).\n",
        "\n",
        "* **Membuat Prediksi**: Untuk membuat prediksi, kita mulai dari *root node* (akar) dan menelusuri cabang-cabang pohon berdasarkan hasil tes pada setiap *node* hingga mencapai *leaf node*. Prediksi akhir adalah label atau nilai yang ada di *leaf node* tersebut.\n",
        "\n",
        "* **Estimasi Probabilitas Kelas**: Selain memprediksi kelas, Decision Tree juga dapat mengestimasi probabilitas sebuah instance termasuk dalam kelas tertentu. Probabilitas ini dihitung sebagai rasio instance dari kelas tersebut di dalam *leaf node* tempat instance tersebut jatuh.\n",
        "\n",
        "* **Algoritma Training CART**: Scikit-Learn menggunakan algoritma **Classification and Regression Tree (CART)**. Algoritma ini bersifat *greedy*, artinya ia mencari pemisahan (*split*) terbaik di setiap level tanpa mempertimbangkan apakah pemisahan tersebut akan menghasilkan solusi optimal secara global beberapa level di bawahnya.\n",
        "    * Untuk klasifikasi, CART mencoba meminimalkan **Gini impurity**. Tujuannya adalah menghasilkan *subset* yang paling \"murni\" (sebagian besar instance di dalamnya berasal dari kelas yang sama).\n",
        "    * Untuk regresi, CART mencoba meminimalkan **Mean Squared Error (MSE)**.\n",
        "\n",
        "* **Regularisasi**: Decision Tree sangat rentan terhadap *overfitting* jika tidak dibatasi. Untuk mengaturnya, digunakan *hyperparameter* regularisasi seperti:\n",
        "    * `max_depth`: Membatasi kedalaman maksimum pohon.\n",
        "    * `min_samples_split`: Jumlah minimum instance yang harus dimiliki sebuah *node* agar bisa dipecah.\n",
        "    * `min_samples_leaf`: Jumlah minimum instance yang harus ada di sebuah *leaf node*.\n",
        "\n",
        "* **Regresi dengan Decision Tree**: Pohon juga bisa digunakan untuk regresi. Prediksi di setiap *leaf node* adalah nilai rata-rata dari target instance yang ada di *node* tersebut. Hasilnya adalah sebuah fungsi prediksi yang berbentuk tangga (*step-wise function*).\n",
        "\n",
        "* **Kelemahan**: Decision Tree sensitif terhadap variasi kecil dalam data training dan rotasi data. Perubahan kecil pada data dapat menghasilkan pohon yang sangat berbeda.\n",
        "\n",
        "### 1. Melatih dan Memvisualisasikan Decision Tree untuk Klasifikasi\n",
        "Kita akan menggunakan dataset Iris yang sudah dikenal.\n",
        "\n",
        "```python\n",
        "# Diperlukan untuk visualisasi di Colab\n",
        "!pip install graphviz\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Memuat dataset Iris\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, 2:] # petal length dan width\n",
        "y = iris.target\n",
        "\n",
        "# Melatih model DecisionTreeClassifier dengan kedalaman maksimum 2\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "tree_clf.fit(X, y)\n",
        "\n",
        "# Mengekspor model ke format .dot\n",
        "dot_data = export_graphviz(\n",
        "        tree_clf,\n",
        "        out_file=None,\n",
        "        feature_names=iris.feature_names[2:],\n",
        "        class_names=iris.target_names,\n",
        "        rounded=True,\n",
        "        filled=True\n",
        "    )\n",
        "\n",
        "# Memvisualisasikan pohon\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n",
        "```\n",
        "Output dari sel di atas adalah visualisasi pohon keputusan yang mudah dibaca. Anda bisa melihat kondisi di setiap *node* (misalnya, `petal width (cm) <= 0.8`), nilai Gini, jumlah *samples*, dan kelas prediksi.\n",
        "\n",
        "### 2. Membuat Prediksi dan Estimasi Probabilitas\n",
        "Setelah pohon dilatih, kita bisa menggunakannya untuk prediksi.\n",
        "\n",
        "```python\n",
        "# Misalkan kita punya bunga dengan petal length 5cm dan petal width 1.5cm\n",
        "# Prediksi probabilitas kelas\n",
        "probabilities = tree_clf.predict_proba([[5, 1.5]])\n",
        "print(\"Estimasi Probabilitas:\", probabilities)\n",
        "\n",
        "# Prediksi kelas\n",
        "predicted_class = tree_clf.predict([[5, 1.5]])\n",
        "print(\"Prediksi Kelas:\", predicted_class)\n",
        "print(f\"Nama Kelas: {iris.target_names[predicted_class[0]]}\")\n",
        "```\n",
        "Berdasarkan pohon yang divisualisasikan, instance ini akan jatuh ke *node* tengah (`value = [0, 49, 5]`), sehingga probabilitas tertinggi adalah untuk kelas *Iris-Versicolor*.\n",
        "\n",
        "### 3. Melatih Decision Tree untuk Regresi\n",
        "Decision Tree juga bisa digunakan untuk tugas regresi.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Membuat data kuadratik dengan noise\n",
        "np.random.seed(42)\n",
        "m = 200\n",
        "X = np.random.rand(m, 1) * 10 - 5\n",
        "y = 0.5 * X**2 + 2 * X + 1 + np.random.randn(m, 1)\n",
        "\n",
        "# Melatih model DecisionTreeRegressor\n",
        "tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg.fit(X, y)\n",
        "\n",
        "def plot_regression_predictions(tree_reg, X, y, axes=[-5, 5, -2, 10]):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
        "    y_pred = tree_reg.predict(x1)\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel(\"$x_1$\")\n",
        "    plt.plot(X, y, \"b.\")\n",
        "    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n",
        "\n",
        "# Plot hasil prediksi\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_regression_predictions(tree_reg, X, y)\n",
        "plt.title(\"Prediksi Regresi dengan Decision Tree (max_depth=2)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "```\n",
        "Plot di atas menunjukkan bahwa prediksi model regresi Decision Tree adalah nilai konstan di dalam setiap wilayah (daun), menghasilkan bentuk seperti tangga. Ini adalah karakteristik utama dari regresi dengan Decision Tree.\n",
        "\n"
      ],
      "metadata": {
        "id": "-0aEJqXVt4eB"
      }
    }
  ]
}