{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNN9Zf6m4jpLqZItbdipnbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keripikkaneboo/Hands-On-Machine-Learning-O-Reilly-/blob/main/17.%20Chapter17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bab 17: Representation Learning and Generative Learning using Autoencoder and GAN\n",
        "\n",
        "Bab ini membahas dua arsitektur jaringan saraf yang kuat untuk pembelajaran tanpa pengawasan (*unsupervised learning*): **Autoencoders** dan **Generative Adversarial Networks (GANs)**. Keduanya mampu mempelajari representasi data yang padat dan efisien (*representation learning*) dan beberapa di antaranya dapat menghasilkan data baru yang realistis (*generative learning*).\n",
        "\n",
        "* **Autoencoders**:\n",
        "    * **Konsep Inti**: Sebuah ANN yang dilatih untuk menyalin inputnya ke outputnya. Ia terdiri dari dua bagian: **encoder** yang mengompresi input menjadi representasi laten (*latent representation* atau *coding*), dan **decoder** yang merekonstruksi input dari *coding* tersebut. Dengan memberikan batasan (misalnya, membuat lapisan *coding* lebih kecil dari input), autoencoder dipaksa untuk belajar fitur-fitur penting dari data.\n",
        "    * **Jenis-jenis Autoencoder**:\n",
        "        * **Stacked Autoencoder**: Autoencoder dengan beberapa *hidden layer*, biasanya simetris.\n",
        "        * **Convolutional & Recurrent Autoencoder**: Menggunakan lapisan konvolusional atau rekuren, cocok untuk data gambar atau sekuensial.\n",
        "        * **Denoising Autoencoder**: Dilatih untuk merekonstruksi input yang bersih dari input yang sudah diberi *noise*. Ini memaksa model untuk belajar fitur yang lebih kuat.\n",
        "        * **Sparse Autoencoder**: Diberi penalti jika lapisan *coding*-nya terlalu aktif, mendorong setiap neuron untuk merepresentasikan fitur yang spesifik dan berguna.\n",
        "        * **Variational Autoencoder (VAE)**: Autoencoder **probabilistik** dan **generatif**. Alih-alih memetakan input ke satu titik di ruang laten, encoder VAE memetakan input ke sebuah distribusi probabilitas (biasanya Gaussian). Ini memungkinkan kita untuk mengambil sampel dari ruang laten untuk menghasilkan data baru yang terlihat realistis.\n",
        "\n",
        "* **Generative Adversarial Networks (GANs)**:\n",
        "    * **Konsep Inti**: GAN terdiri dari dua jaringan saraf yang saling bersaing:\n",
        "        1.  **Generator**: Mencoba membuat data palsu yang terlihat nyata (misalnya, gambar wajah palsu).\n",
        "        2.  **Discriminator**: Mencoba membedakan antara data asli dan data palsu yang dibuat oleh generator.\n",
        "    * **Adversarial Training**: Selama training, generator dan diskriminator bermain game *zero-sum*. Generator menjadi lebih baik dalam \"menipu\" diskriminator, sementara diskriminator menjadi lebih baik dalam \"menangkap\" pemalsuan. Kompetisi ini mendorong kedua jaringan untuk menjadi lebih baik.\n",
        "    * **Tantangan Training GAN**: Training GAN terkenal sulit karena dinamikanya yang tidak stabil. Masalah umum termasuk:\n",
        "        * **Mode Collapse**: Generator hanya menghasilkan variasi data yang sangat terbatas (misalnya, hanya satu jenis wajah).\n",
        "        * **Konvergensi yang Tidak Stabil**: Proses training bisa tiba-tiba menyimpang.\n",
        "    * **Arsitektur GAN Lanjutan**:\n",
        "        * **Deep Convolutional GAN (DCGAN)**: Memberikan panduan arsitektur untuk membangun GAN yang stabil menggunakan lapisan konvolusional.\n",
        "        * **Progressive GANs**: Melatih GAN dengan cara menghasilkan gambar beresolusi rendah terlebih dahulu, lalu secara bertahap meningkatkan resolusinya.\n",
        "        * **StyleGANs**: Arsitektur canggih yang memisahkan \"gaya\" (*style*) dari konten gambar, memungkinkan kontrol yang lebih baik dan menghasilkan gambar yang sangat realistis.\n",
        "\n",
        "### 1. Stacked Autoencoder dengan Keras\n",
        "Contoh sederhana untuk mengompresi dan merekonstruksi gambar Fashion MNIST.\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Memuat dan mempersiapkan data Fashion MNIST\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train = X_train_full.astype(np.float32) / 255\n",
        "X_valid = X_train[:5000]\n",
        "X_train = X_train[5000:]\n",
        "\n",
        "# Membangun stacked autoencoder\n",
        "stacked_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\"), # Lapisan coding\n",
        "])\n",
        "\n",
        "stacked_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
        "\n",
        "stacked_ae.compile(loss=\"binary_crossentropy\",\n",
        "                   optimizer=keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "# history = stacked_ae.fit(X_train, X_train, epochs=20,\n",
        "#                          validation_data=(X_valid, X_valid))\n",
        "print(\"Stacked autoencoder telah dibuat dan dikompilasi.\")\n",
        "```\n",
        "\n",
        "### 2. Variational Autoencoder (VAE) untuk Menghasilkan Gambar\n",
        "VAE adalah model generatif. Setelah dilatih, kita bisa menggunakannya untuk membuat gambar baru.\n",
        "\n",
        "```python\n",
        "# Lapisan kustom untuk sampling\n",
        "class Sampling(keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + mean\n",
        "\n",
        "codings_size = 10\n",
        "\n",
        "# Membangun encoder VAE\n",
        "inputs = keras.layers.Input(shape=[28, 28])\n",
        "z = keras.layers.Flatten()(inputs)\n",
        "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
        "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
        "codings_mean = keras.layers.Dense(codings_size)(z)       # μ\n",
        "codings_log_var = keras.layers.Dense(codings_size)(z)    # γ = log(σ^2)\n",
        "codings = Sampling()([codings_mean, codings_log_var])\n",
        "variational_encoder = keras.Model(\n",
        "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
        "\n",
        "# Membangun decoder VAE\n",
        "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
        "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
        "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
        "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
        "outputs = keras.layers.Reshape([28, 28])(x)\n",
        "variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
        "\n",
        "# Menggabungkan menjadi VAE\n",
        "_, _, codings = variational_encoder(inputs)\n",
        "reconstructions = variational_decoder(codings)\n",
        "variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])\n",
        "\n",
        "# Menambahkan latent loss\n",
        "latent_loss = -0.5 * tf.reduce_sum(\n",
        "    1 + codings_log_var - tf.exp(codings_log_var) - tf.square(codings_mean),\n",
        "    axis=-1)\n",
        "variational_ae.add_loss(tf.reduce_mean(latent_loss) / 784.0)\n",
        "\n",
        "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "# history = variational_ae.fit(X_train, X_train, epochs=25, batch_size=128,\n",
        "#                                validation_data=(X_valid, X_valid))\n",
        "print(\"\\nVariational Autoencoder (VAE) telah dibuat.\")\n",
        "```\n",
        "Setelah melatih VAE, Anda dapat memanggil `variational_decoder.predict()` dengan input acak dari distribusi normal untuk menghasilkan gambar baru.\n",
        "\n",
        "### 3. Generative Adversarial Network (GAN)\n",
        "Contoh GAN sederhana untuk Fashion MNIST. Training GAN memerlukan *custom training loop*.\n",
        "\n",
        "```python\n",
        "# Membangun generator dan diskriminator\n",
        "codings_size = 30\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "\n",
        "# Mengompilasi model\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False # Penting: bekukan diskriminator saat melatih generator\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "# Custom Training Loop (kerangka)\n",
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        # print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
        "        for X_batch in dataset:\n",
        "            # Fase 1: Melatih diskriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "\n",
        "            # Fase 2: Melatih generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        # Tampilkan hasil atau simpan gambar yang dihasilkan di akhir setiap epoch\n",
        "\n",
        "# batch_size = 32\n",
        "# dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "# dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "# train_gan(gan, dataset, batch_size, codings_size)\n",
        "print(\"\\nGenerative Adversarial Network (GAN) telah dibuat.\")\n",
        "```\n",
        "Training GAN sangat sensitif dan mungkin memerlukan banyak *tuning*. Kode di atas menunjukkan logika dasar dari proses training-nya.\n"
      ],
      "metadata": {
        "id": "-0aEJqXVt4eB"
      }
    }
  ]
}