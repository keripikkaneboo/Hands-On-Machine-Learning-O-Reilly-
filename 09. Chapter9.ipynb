{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMAaFFf77lGArlw+c9GalE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keripikkaneboo/Hands-On-Machine-Learning-O-Reilly-/blob/main/09.%20Chapter9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bab 9: Unsupervised Learning Techniques\n",
        "\n",
        "Bab ini membahas **Unsupervised Learning**, di mana algoritma belajar dari data yang tidak memiliki label. Fokusnya adalah pada tiga tugas utama:\n",
        "1.  **Clustering**: Mengelompokkan instance yang mirip ke dalam grup atau *cluster*.\n",
        "2.  **Anomaly Detection**: Mendeteksi instance yang sangat menyimpang dari norma (*outlier*).\n",
        "3.  **Density Estimation**: Mengestimasi fungsi kepadatan probabilitas (PDF) dari data.\n",
        "\n",
        "* **Clustering**:\n",
        "    * **K-Means**: Salah satu algoritma clustering yang paling populer. Ia bekerja dengan cara:\n",
        "        1.  Menempatkan *k* buah *centroid* secara acak.\n",
        "        2.  Memberi label pada setiap instance berdasarkan *centroid* terdekat.\n",
        "        3.  Memperbarui posisi *centroid* dengan menghitung rata-rata dari semua instance dalam clusternya.\n",
        "        4.  Mengulangi langkah 2 dan 3 hingga *centroid* tidak lagi bergerak.\n",
        "        * **Kelemahan**: Harus menentukan jumlah cluster (*k*), sensitif terhadap inisialisasi, dan kesulitan menangani cluster dengan bentuk non-bola, ukuran bervariasi, atau kepadatan yang berbeda.\n",
        "        * **Menemukan *k***: Teknik seperti **Elbow Method** (menggunakan metrik *inertia*) dan **Silhouette Score** dapat membantu menemukan jumlah cluster yang optimal.\n",
        "    * **DBSCAN** (*Density-Based Spatial Clustering of Applications with Noise*): Algoritma yang mendefinisikan cluster sebagai wilayah padat yang berkesinambungan.\n",
        "        * Sangat baik dalam menemukan cluster dengan bentuk yang arbitrer (tidak harus bola).\n",
        "        * Tahan terhadap *outlier* (menganggapnya sebagai *noise*).\n",
        "        * Tidak mengharuskan kita untuk menentukan jumlah cluster, tetapi memerlukan pengaturan *hyperparameter* `eps` (radius lingkungan) dan `min_samples`.\n",
        "\n",
        "* **Gaussian Mixture Models (GMM)**:\n",
        "    * Model probabilistik yang mengasumsikan data berasal dari campuran beberapa distribusi Gaussian dengan parameter yang tidak diketahui.\n",
        "    * Setiap cluster dapat memiliki bentuk elips, ukuran, kepadatan, dan orientasi yang berbeda, membuatnya lebih fleksibel daripada K-Means.\n",
        "    * Dilatih menggunakan algoritma **Expectation-Maximization (EM)**.\n",
        "    * **Aplikasi**: Dapat digunakan untuk *density estimation*, *clustering*, dan *anomaly detection*.\n",
        "    * **Memilih Jumlah Cluster**: Dapat menggunakan kriteria informasi seperti **BIC** (*Bayesian Information Criterion*) atau **AIC** (*Akaike Information Criterion*). Model **Bayesian GMM** bahkan dapat secara otomatis menemukan jumlah cluster yang optimal.\n",
        "\n",
        "### 1. K-Means\n",
        "Pertama, kita akan membuat data sintetis untuk mendemonstrasikan K-Means.\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Membuat dataset dengan 5 blob (cluster)\n",
        "blob_centers = np.array(\n",
        "    [[ 0.2,  2.3], [-1.5 ,  2.3], [-2.8,  1.8], [-2.8,  2.8], [-2.8,  1.3]])\n",
        "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
        "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
        "                  cluster_std=blob_std, random_state=7)\n",
        "\n",
        "# Melatih model K-Means\n",
        "k = 5\n",
        "kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "y_pred = kmeans.fit_predict(X)\n",
        "\n",
        "# y_pred berisi label cluster untuk setiap instance\n",
        "# kmeans.cluster_centers_ berisi lokasi centroid\n",
        "print(\"Lokasi Centroid:\\n\", kmeans.cluster_centers_)\n",
        "\n",
        "# Fungsi untuk mem-plot cluster\n",
        "def plot_clusters(X, y=None, centroids=None, k=None):\n",
        "    if y is not None:\n",
        "        plt.scatter(X[:, 0], X[:, 1], c=y, s=1)\n",
        "    else:\n",
        "        plt.scatter(X[:, 0], X[:, 1], s=1)\n",
        "    if centroids is not None:\n",
        "        plt.scatter(centroids[:, 0], centroids[:, 1], s=50, c='red', marker='x')\n",
        "    if k:\n",
        "      plt.title(f\"k={k}\")\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_clusters(X, y=y_pred, centroids=kmeans.cluster_centers_, k=k)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### 2. Menemukan Jumlah Cluster Optimal (Elbow Method & Silhouette Score)\n",
        "Kita tidak selalu tahu jumlah cluster yang tepat. Dua metode berikut dapat membantu.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# --- Elbow Method (menggunakan inertia) ---\n",
        "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X)\n",
        "                for k in range(1, 10)]\n",
        "inertias = [model.inertia_ for model in kmeans_per_k]\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(121)\n",
        "plt.plot(range(1, 10), inertias, \"bo-\")\n",
        "plt.xlabel(\"$k$\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method\")\n",
        "plt.grid(True)\n",
        "\n",
        "# --- Silhouette Score ---\n",
        "silhouette_scores = [silhouette_score(X, model.labels_)\n",
        "                     for model in kmeans_per_k[1:]] # score butuh minimal 2 cluster\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
        "plt.xlabel(\"$k$\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.title(\"Silhouette Score\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "```\n",
        "Dari plot di atas, \"siku\" pada metode *elbow* terlihat jelas di k=5. Demikian pula, *silhouette score* mencapai puncaknya di k=5, mengonfirmasi bahwa 5 adalah jumlah cluster yang baik.\n",
        "\n",
        "### 3. DBSCAN\n",
        "DBSCAN sangat baik untuk cluster dengan bentuk non-bola, seperti dataset `moons`.\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Membuat dataset moons\n",
        "X, y = make_moons(n_samples=1000, noise=0.05, random_state=42)\n",
        "\n",
        "# Melatih model DBSCAN\n",
        "# eps adalah radius lingkungan, min_samples adalah jumlah tetangga minimum\n",
        "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
        "dbscan.fit(X)\n",
        "\n",
        "# Label -1 menunjukkan outlier/noise\n",
        "print(\"Label unik dari DBSCAN:\", np.unique(dbscan.labels_))\n",
        "\n",
        "# Plot hasil\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_clusters(X, y=dbscan.labels_)\n",
        "plt.title(\"Hasil DBSCAN\")\n",
        "plt.show()\n",
        "```\n",
        "DBSCAN berhasil mengidentifikasi dua cluster berbentuk bulan sabit dengan benar, sesuatu yang tidak bisa dilakukan oleh K-Means.\n",
        "\n",
        "### 4. Gaussian Mixture Models (GMM)\n",
        "GMM dapat menangani cluster berbentuk elips dengan baik.\n",
        "\n",
        "```python\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Menggunakan data blob dari contoh K-Means\n",
        "gmm = GaussianMixture(n_components=5, n_init=10, random_state=42)\n",
        "gmm.fit(X)\n",
        "\n",
        "# Memprediksi cluster\n",
        "y_pred_gmm = gmm.predict(X)\n",
        "\n",
        "# Plot hasil\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_clusters(X, y=y_pred_gmm, centroids=gmm.means_, k=5)\n",
        "plt.title(\"Hasil Gaussian Mixture Model\")\n",
        "plt.show()\n",
        "\n",
        "# Menghitung BIC dan AIC untuk memilih jumlah komponen\n",
        "bics = [GaussianMixture(n_components=k, n_init=10, random_state=42).fit(X).bic(X)\n",
        "        for k in range(1, 10)]\n",
        "aics = [GaussianMixture(n_components=k, n_init=10, random_state=42).fit(X).aic(X)\n",
        "        for k in range(1, 10)]\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(range(1, 10), bics, \"bo-\", label=\"BIC\")\n",
        "plt.plot(range(1, 10), aics, \"go--\", label=\"AIC\")\n",
        "plt.xlabel(\"$k$\")\n",
        "plt.ylabel(\"Information Criterion\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "Plot BIC/AIC menunjukkan bahwa nilai terendah ada di k=5, yang sesuai dengan jumlah cluster sebenarnya dalam data kita.\n",
        "\n"
      ],
      "metadata": {
        "id": "-0aEJqXVt4eB"
      }
    }
  ]
}