{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWZRhEZf4yeWZMTLySHP1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keripikkaneboo/Hands-On-Machine-Learning-O-Reilly-/blob/main/02.%20Chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bab 2: End to End Machine Learning Project\n",
        "\n",
        "Bab ini memandu pembaca melalui contoh proyek ML secara lengkap, dari awal hingga akhir, menggunakan dataset **California Housing Prices**. Tujuannya adalah untuk membangun model yang dapat memprediksi harga median rumah di sebuah distrik.\n",
        "\n",
        "### 1. Mendapatkan Data\n",
        "\n",
        "Langkah pertama adalah mengunduh dan memuat dataset. Kita akan membuat beberapa fungsi untuk mengotomatiskan proses ini.\n",
        "\n",
        "```python\n",
        "# Diperlukan untuk Google Colab\n",
        "# Menyiapkan environment\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "# Lokasi download dan path penyimpanan data\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "# Fungsi untuk mengunduh dan mengekstrak data\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()\n",
        "\n",
        "# Menjalankan fungsi download\n",
        "fetch_housing_data()\n",
        "\n",
        "# Fungsi untuk memuat data CSV ke dalam pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "housing = load_housing_data()\n",
        "```\n",
        "\n",
        "### 2. Inspeksi Awal Data\n",
        "Setelah data dimuat, kita perlu melihat struktur dan ringkasan statistiknya untuk mendapatkan pemahaman awal.\n",
        "\n",
        "```python\n",
        "# Menampilkan 5 baris pertama\n",
        "print(\"Lima baris pertama:\")\n",
        "print(housing.head())\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Menampilkan informasi ringkas (tipe data, nilai non-null)\n",
        "print(\"Informasi dataset:\")\n",
        "housing.info()\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Melihat ringkasan statistik fitur numerik\n",
        "print(\"Deskripsi statistik:\")\n",
        "print(housing.describe())\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Melihat distribusi data dengan histogram\n",
        "import matplotlib.pyplot as plt\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### 3. Membuat Test Set (Stratified Sampling)\n",
        "Penting untuk menyisihkan *test set* sejak awal untuk mencegah *data snooping bias*. Kita akan menggunakan *stratified sampling* berdasarkan kategori pendapatan untuk memastikan *test set* representatif.\n",
        "\n",
        "```python\n",
        "# Membuat kategori pendapatan untuk stratified sampling\n",
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]\n",
        "\n",
        "# Menghapus kolom income_cat karena hanya digunakan untuk splitting\n",
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
        "\n",
        "# Membuat salinan data training untuk eksplorasi\n",
        "housing = strat_train_set.copy()\n",
        "```\n",
        "\n",
        "### 4. Persiapan Data (Preprocessing Pipeline)\n",
        "Tahap ini adalah yang paling krusial, di mana kita membersihkan dan mentransformasi data agar siap digunakan oleh model. Kita akan membangun sebuah *pipeline* untuk menangani fitur numerik dan kategorikal secara terpisah.\n",
        "\n",
        "```python\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Memisahkan fitur dari label\n",
        "housing_labels = housing[\"median_house_value\"].copy()\n",
        "housing = housing.drop(\"median_house_value\", axis=1)\n",
        "\n",
        "# Mengambil nama kolom numerik dan kategorikal\n",
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "# Pipeline untuk fitur numerik: mengisi nilai kosong & menstandardisasi\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "# Pipeline penuh yang menggabungkan proses numerik dan kategorikal\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "# Menjalankan pipeline pada data training\n",
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "```\n",
        "\n",
        "### 5. Memilih dan Melatih Model\n",
        "Kita akan melatih beberapa model dan mengevaluasinya menggunakan *cross-validation* untuk memilih yang terbaik.\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Inisialisasi model\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Evaluasi model menggunakan cross-validation\n",
        "scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())\n",
        "\n",
        "print(\"Hasil Evaluasi RandomForestRegressor:\")\n",
        "display_scores(rmse_scores)\n",
        "```\n",
        "\n",
        "### 6. Fine-Tuning Model\n",
        "Setelah memilih model terbaik, kita mencari kombinasi *hyperparameter* optimal menggunakan `GridSearchCV`.\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definisikan grid hyperparameter yang akan diuji\n",
        "param_grid = [\n",
        "    {'n_estimators': [10, 30, 50], 'max_features': [6, 8, 10]},\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "  ]\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Menjalankan grid search\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "grid_search.fit(housing_prepared, housing_labels)\n",
        "\n",
        "# Menampilkan hyperparameter terbaik\n",
        "print(\"\\nHyperparameter terbaik:\", grid_search.best_params_)\n",
        "```\n",
        "\n",
        "### 7. Evaluasi Akhir pada Test Set\n",
        "Terakhir, kita mengevaluasi model final pada *test set* yang telah kita sisihkan sejak awal.\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Model terbaik dari Grid Search\n",
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "# Memisahkan fitur dan label dari test set\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "# Menjalankan pipeline pada test set (hanya transform, bukan fit_transform)\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "\n",
        "# Membuat prediksi\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "# Menghitung RMSE final\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(\"\\nRMSE final pada test set:\", final_rmse)\n",
        "```\n"
      ],
      "metadata": {
        "id": "-0aEJqXVt4eB"
      }
    }
  ]
}